### 从一道争议的概率题谈概率建模与推理 --- 隐式变量建模与推理

The first note for Probabilistic Modelling and Reasoning (PMR) --- Probabilistic modelling with Hidden variables and inference

cr：@吃竹叶的胖达（bilibili），转载必附原作者与原文链接地址，禁止一切侵犯知识产权的行为，违者必按照欧盟GDPR知识产权保护条例追究其侵权行为。



打算写这一篇入门科普文是从@魔法小分队队长提出的一道争议的概率题目开始的；正巧这道题目我之前在海外研究生的机器学习的课上听过这个，并且这是一道PMR入门的基础题目，所以打算为准备入门概率建模与推理的童鞋写一写这方面的科普。本来打算出一期思路讲解视频的，但昨天去郊外探险，嗓子哑了，所以用这篇文章代替。



题目是这样的：三个相同盒子各有两个球，一个放了两个红球，一个一红一蓝，还有一个两个蓝球。随机选择一个盒子，摸出一个球发现是红球，求另一个球也是红球的概率。



这是一个典型的隐式变量建模与推理的题目，隐式变量建模与推理有很多的应用，最著名的一个我颁奖给HMM（隐式马尔科夫模型，Hidden Markov Model）。在建模之前先声明几个基本概率学概念，以及澄清一下@魔法小分队队长在视频中理论分析部分中的知识点错误。以下均假设随机变量用英文大写字母表示，随机变量是离散型变量（对于continuous variables，类似公式将求和变成积分）：

* 联合概率分布（joint probability distribution）：$$p(X,Y)$$
* 条件概率分布（conditional probability distribution）：$$p(X|Y)$$
* Marginal probability distribution: $$p(X)$$
* 概率学的乘法公式：$$p(X,Y) = p(X|Y)*p(Y) $$
* 概率学的加法公式：$$p(X) = \sum\limits_Y p(X,Y)$$
* Bayesian law (贝叶斯公式)：$$p(Y|X) = \dfrac{p(X,Y)}{p(X)} = \dfrac{p(X|Y)*p(Y)}{p(X)}​$$

这里为了加深大家对贝叶斯公式的理解，对其做一些说明。贝叶斯公式是做推理（Inference/Reasoning）的重要公式；如果将随机变量Y看成是我们建立模型中的参数（比如待求的概率，建模时候的参数），X看成是观测值或者结果（如实验测量，measurement），那么公式中的条件概率$$p(Y|X) $$表示我们基于了一些观测值后，我们认为的模型中的参数（$$Y|X$$）的概率分布，亦称后验概率（posterior）；等式右边的条件概率$$p(X|Y) $$是由我们建立的模型给出来的，是在基于一组参数Y的情况下出现观测值X的概率分布，我们称为可能性或似然值（likelihood）；marginal distribution $$p(Y)$$ 是我们在完全没有见过观测值X之前对参数分布Y的判断，称为前验概率（prior）；marginal distribution $$p(X)$$ 是一组数据或观测值出现的概率。贝叶斯公式告诉了我们可以通过模型得出的likelihood和prior得出基于一组观测值后的posterior，即做出根据观测值的推理（Inference），这也就是machine learning 和 PMR的核心。



那我们回到问题上来，对这个问题进行建模，显然这个题目有一个隐式变量，就是我们摸出的盒子是哪一个，那么我们假设摸出的盒子为随机变量Y，摸出第一个球的颜色是随机变量X，摸出第二个球是随机变量Z，标记红球为a，蓝球为b，盒子编号1,2,3；那么我们就来建模看看X，Y，Z之间有什么关系：

1. 已知：i. prior information: $$p(Y=1)=p(Y=2)=p(Y=3)=\frac{1}{3}.​$$

   ii. model info: $$p(X=a|Y=1)=1​$$; $$p(X=a|Y=2)=\frac{1}{2}​$$; $$p(X=a|Y=3)=0​$$

   iii. model info: $$p(Z=a|X=a, Y=1) = 1$$; $$p(Z=a|X=a, Y=2) = 0$$; $$p(Z=a|X=a, Y=3) = 0$$ (undefined, actually)

2. 求 $$p(Z=a|X=a)​$$



建模后，我们发现这个问题是一个典型的隐式变量建模与推理的问题，观察结果是随机变量X，要求基于这个观测结果下的模型参数Z的概率分布。在建模转换之后的问题就很简单了，利用加法公式消去hidden variable Y即可：$$p(Z=a|X=a) = \sum\limits_Y p(Z=a ,Y|X=a) = \sum\limits_{Y=1,2,3} p(Z=a|X=a, Y) *p(Y|X=a)​$$

其中，$$p(Z=a|X=a, Y)​$$部分由已知信息iii. model info给出；posterior $$p(Y|X=a)​$$ 由贝叶斯公式得出：

$$p(Y|X=a) = \dfrac{p(X=a|Y) *p(Y)}{p(X=a)} = \dfrac{p(X=a|Y) *p(Y)}{\sum\limits_{Y=1,2,3}p(X=a|Y) *p(Y)}$$

代入所有数据可以得到和@魔法小分队队长实验仿真一样的结果$$p(Z=a|X=a) = \dfrac{2}{3}​$$。





后记：解决完问题，我们发现在理解了基本概念之后，问题的确很简单，但为什么还会有巨大的分歧呢？思前想后，我把问题的关键归因于大家不习惯对于一个问题进行详尽的数学描述与数学建模，对于这种Inference类的只是喜欢凭着个人的理解和想象去推断。此外对于没接触过且尝试建模的童鞋，这里的引入hidden variable去完全数学表达概率是一个难点。因此，我给对概率建模与推理感兴趣的童鞋的建议是，不要完全相信自己的推理，把推理的任务交给贝叶斯去做吧。



欢迎关注我呀，我是bilibili、吃竹叶的胖达，后期会出很多机器学习、自然语言处理、PMR、博弈论、强化学习（RL）相关的入门教程贴的，欢迎关注转发评论投币~

